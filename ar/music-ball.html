<!DOCTYPE html>

<head>
	<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
	<title>Hello, AR Cube!</title>

	<script src='js/simplex-noise.js'></script>
	<!-- include three.js library -->
	<script src='js/three.js'></script>
	<!-- include jsartookit -->
	<script src="jsartoolkit5/artoolkit.min.js"></script>
	<script src="jsartoolkit5/artoolkit.api.js"></script>
	<!-- include threex.artoolkit -->
	<script src="threex/threex-artoolkitsource.js"></script>
	<script src="threex/threex-artoolkitcontext.js"></script>
	<script src="threex/threex-arbasecontrols.js"></script>
	<script src="threex/threex-armarkercontrols.js"></script>
	<style>
		html,
		body {
			font-family: 'Saira', sans-serif;
			font-size: small;
		}

		canvas {
			margin-top: 100px !important;
		}

		video {
			margin-top: 100px !important;
		}

		.content {
			display: flex;
			flex-direction: column;
			align-items: center;
			justify-content: center;
			margin-top: 10px;
		}

		input#thefile {
			margin: 0px 8px 3px;
		}
	</style>
</head>

<body style='margin : 0px; overflow: hidden;'>

	<!-- 
  Example created by Lee Stemkoski: https://github.com/stemkoski
  Based on the AR.js library and examples created by Jerome Etienne: https://github.com/jeromeetienne/AR.js/
-->
	<!--
	Audio visualization with guidance from https://medium.com/@mag_ops/music-visualiser-with-three-js-web-audio-api-b30175e7b5ba
-->
	<!--
	file:///C:/pinkbluesky.github.io/ar/music-cubes.html
-->


	<div class="content">
		<label for="thefile" class="file"> Choose an audio file
			<input type="file" id="thefile" accept="audio/*" />
		</label>
		<audio id="audio" controls></audio>
		<div id="out"></div>

	</div>

	<script>

		var scene, camera, renderer, clock, deltaTime, totalTime;

		var arToolkitSource, arToolkitContext;

		var markerRoot1, markerRoot2;

		var mesh1;

		var audioCtx, source, analyser, dataArray;

		var ball;

		var noise; // simplexnoise instance


		var file, audio, fileLabel;

		initialize();
		animate();

		function play() {
			audioCtx = new AudioContext();
			source = context.createMediaElementSource(audio);
			analyser = context.createAnalyser();
			source.connect(analyser);
			analyser.connect(audioCtx.destination);
			analyser.fftSize = 512;
			var bufferLength = analyser.frequencyBinCount;
			dataArray = new Uint8Array(bufferLength);

			////////////////////////////////////////////////////////////
			// setup audio
			////////////////////////////////////////////////////////////

			/*
						dataArray = [];
						audioCtx = null;
			
						// initialize Web Audio API
						if (navigator.mediaDevices) {
							console.log("getUserMedia supported.");
							navigator.mediaDevices.getUserMedia({ audio: true })
								.then(function (stream) {
			
									audioCtx = new AudioContext();
									source = audioCtx.createMediaStreamSource(stream);
			
									console.log(audioCtx);
									analyser = audioCtx.createAnalyser();
									source.connect(analyser);
									analyser.connect(audioCtx.destination);
									analyser.fftSize = 2048;
									var bufferLength = analyser.frequencyBinCount;
									dataArray = new Uint8Array(bufferLength);
								}
								).catch(function (err) { console.log('The following gUM error occurred' + err) });
						}
						else {
							console.log("getUserMedia not supported/blocked on your browser!");
						}
			*/

			////////////////////////////////////////////////////////////
			// setup scene
			////////////////////////////////////////////////////////////

			let sceneGroup = new THREE.Group();
			markerRoot1.add(sceneGroup);

			ball = new THREE.Mesh(new THREE.IcosahedronGeometry(1, 4),
				new THREE.MeshLambertMaterial({
					color: 0xff00ee,
					wireframe: true
				}));
			ball.position.set(0, 0, 0);
			sceneGroup.add(ball);

			var planeGeometry = new THREE.PlaneGeometry(800, 800, 20, 20);
			var planeMaterial = new THREE.MeshLambertMaterial({
				color: 0x6904ce,
				side: THREE.DoubleSide,
				wireframe: true
			});

			var plane = new THREE.Mesh(planeGeometry, planeMaterial);
			plane.rotation.x = -0.5 * Math.PI;
			plane.position.set(0, 30, 0);
			sceneGroup.add(plane);

			var plane2 = new THREE.Mesh(planeGeometry, planeMaterial);
			plane2.rotation.x = -0.5 * Math.PI;
			plane2.position.set(0, -30, 0);
			sceneGroup.add(plane2);

			sceneGroup.rotation.y += 0.005;

		}

		function initialize() {


			file = document.getElementById("thefile");
			audio = document.getElementById("audio");
			fileLabel = document.querySelector("label.file");

			clock = new THREE.Clock();
			deltaTime = 0;
			totalTime = 0;


			scene = new THREE.Scene();

			let ambientLight = new THREE.AmbientLight(0xcccccc, 0.5);
			scene.add(ambientLight);

			camera = new THREE.PerspectiveCamera(45, window.innerWidth / window.innerHeight, 0.1, 1000);
			camera.position.set(0, 0, 100);
			camera.lookAt(scene.position);
			scene.add(camera);

			renderer = new THREE.WebGLRenderer({
				antialias: true,
				alpha: true
			});
			renderer.setClearColor(new THREE.Color('lightgrey'), 0)
			renderer.setSize(window.innerWidth, window.innerHeight);
			renderer.domElement.style.position = 'absolute'
			renderer.domElement.style.top = '0px'
			renderer.domElement.style.left = '0px'
			document.body.appendChild(renderer.domElement);



			document.onload = function (e) {
				console.log(e);
				audio.play();
				play();
			}

			noise = new SimplexNoise();

			////////////////////////////////////////////////////////////
			// setup arToolkitSource
			////////////////////////////////////////////////////////////

			arToolkitSource = new THREEx.ArToolkitSource({
				sourceType: 'webcam',
			});

			function onResize() {
				arToolkitSource.onResize()
				arToolkitSource.copySizeTo(renderer.domElement)
				if (arToolkitContext.arController !== null) {
					arToolkitSource.copySizeTo(arToolkitContext.arController.canvas)
				}
			}

			arToolkitSource.init(function onReady() {
				onResize()
			});

			// handle resize event
			window.addEventListener('resize', function () {
				onResize()
			});

			////////////////////////////////////////////////////////////
			// setup arToolkitContext
			////////////////////////////////////////////////////////////	

			// create atToolkitContext
			arToolkitContext = new THREEx.ArToolkitContext({
				cameraParametersUrl: 'data/camera_para.dat',
				detectionMode: 'mono'
			});

			// copy projection matrix to camera when initialization complete
			arToolkitContext.init(function onCompleted() {
				camera.projectionMatrix.copy(arToolkitContext.getProjectionMatrix());
			});

			////////////////////////////////////////////////////////////
			// setup markerRoots
			////////////////////////////////////////////////////////////

			// build markerControls
			markerRoot1 = new THREE.Group();
			scene.add(markerRoot1);
			let markerControls1 = new THREEx.ArMarkerControls(arToolkitContext, markerRoot1, {
				type: 'pattern', patternUrl: "data/hiro.patt",
			})



		}


		function update() {

			file = document.getElementById("thefile");
			audio = document.getElementById("audio");
			fileLabel = document.querySelector("label.file");

			file.onchange = function () {
				fileLabel.classList.add('normal');
				audio.classList.add('active');
				var files = this.files;

				audio.src = URL.createObjectURL(files[0]);
				audio.load();
				audio.play();
				play();
			}

			// update artoolkit on every frame
			if (arToolkitSource.ready !== false)
				arToolkitContext.update(arToolkitSource.domElement);


			if (dataArray && analyser) {
				analyser.getByteFrequencyData(dataArray);
				var lowerHalf = dataArray.slice(0, (dataArray.length / 2) - 1);
				var upperHalf = dataArray.slice((dataArray.length / 2) - 1, dataArray.length - 1);

				var overallAvg = avg(dataArray);
				var lowerMaxFr = max(lowerHalf) / lowerHalf.length;
				var lowerAvgFr = avg(lowerHalf) / lowerHalf.length;
				var upperMaxFr = max(upperHalf) / upperHalf.length;
				var upperAvgFr = avg(upperHalf) / upperHalf.length;

				makeRoughBall(ball,
					modulate(Math.pow(lowerMaxFr, 0.8), 0, 1, 0, 8),
					modulate(upperAvgFr, 0, 1, 0, 4));

			}

		}

		function render() {
			renderer.render(scene, camera);
		}


		function animate() {
			requestAnimationFrame(animate);
			deltaTime = clock.getDelta();
			totalTime += deltaTime;
			update();
			render();
		}

		function makeRoughBall(mesh, bassFr, treFr) {
			mesh.geometry.vertices.forEach(function (vertex, i) {
				var offset = mesh.geometry.parameters.radius;
				var amp = 7;
				var time = window.performance.now();
				vertex.normalize();

				var rf = 0.00001;
				var distance = (offset + bassFr)
					+ noise.noise3D(vertex.x + time * rf * 7, vertex.y + time * rf * 8, vertex.z + time * rf * 9) * amp * treFr;
				vertex.multiplyScalar(distance);
			});

			mesh.geometry.verticesNeedUpdate = true;
			mesh.geometry.normalsNeedUpdate = true;
			mesh.geometry.computeVertexNormals();
			mesh.geometry.computeFaceNormals();
		}

		function makeRoughGround(mesh, distortionFr) {
			mesh.geometry.vertices.forEach(function (vertex, i) {
				var amp = 2;
				var time = Date.now();
				var distance = (noise.noise2D(vertex.x + time * 0.0003, vertex.y + time * 0.0001) + 0) * distortionFr * amp;
				vertex.z = distance;
			});
			mesh.geometry.verticesNeedUpdate = true;
			mesh.geometry.normalsNeedUpdate = true;
			mesh.geometry.computeVertexNormals();
			mesh.geometry.computeFaceNormals();
		}

		// helper functions: avg, min, max for audio visualization

		function fractionate(val, minVal, maxVal) {
			return (val - minVal) / (maxVal - minVal);
		}

		// basically squishing frequencies into a certain outMin to outMax range
		function modulate(val, minVal, maxVal, outMin, outMax) {
			var fr = fractionate(val, minVal, maxVal);
			var delta = outMax - outMin;
			return outMin + (fr * delta);
		}

		// returns the average of an array
		function avg(arr) {
			var total = arr.reduce(function (sum, b) { return sum + b; });
			return total / arr.length;
		}

		function max(arr) {
			return arr.reduce(function (a, b) { return Math.max(a, b); });
		}

	</script>

</body>

</html>